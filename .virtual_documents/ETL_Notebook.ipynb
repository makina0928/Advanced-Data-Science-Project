





import pandas as pd
import os

def read_and_append_excel_files(directory):
    """
    Read the 'Data' tab of all Excel files in a specified directory 
    and append them into a single DataFrame without creating intermediate DataFrames.

    Parameters:
    directory (str): The path to the directory containing the Excel files.

    Returns:
    DataFrame: A single DataFrame containing the appended data from all the 'Data' tabs.
    """
    appended_df = pd.DataFrame()  # Start with an empty DataFrame

    try:
        # Iterate over all files in the directory
        for filename in os.listdir(directory):
            if filename.endswith('.xlsx') or filename.endswith('.xls'):
                file_path = os.path.join(directory, filename)
                try:
                    # Read the 'Data' sheet from the Excel file
                    df = pd.read_excel(file_path, sheet_name='Data')
                    # Append data to the existing DataFrame
                    appended_df = pd.concat([appended_df, df], ignore_index=True)
                    print(f"Read 'Data' from {file_path}")
                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
    except Exception as e:
        print(f"An error occurred: {e}")

    return appended_df

# Example usage:
directory = 'C:\\Data\\Projects\\ETL-Pipeline\\RawData'
appended_df = read_and_append_excel_files(directory)
appended_df.head(3)



# Define a custom function for retrieving some information from the dataframe
def print_dataframe_info(data):
    if isinstance(data, pd.DataFrame):
        info = data.info()
        null = data.isna().sum()
        
        print(f"{info}")
        print(f"..........Null Count:........... ")
        print(f"{null}")
    else:
        print(f"Skipping non-DataFrame object: {data}")

# Use the function for appended_df DataFrame
print_dataframe_info(appended_df)


import warnings
warnings.filterwarnings(action='ignore')


# Function to identify column types
def identify_and_clean(df):
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()

    # Handle missing values
    df[categorical_cols] = df[categorical_cols].fillna('Unknown')
    df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())

    # Clean categorical columns
    for col in categorical_cols:
        df[col] = df[col].str.strip().str.lower()

    # Convert Date column if present
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'], errors = 'coerce') # Convert and handle invalid dates

    # Clean numerical columns
    for col in numerical_cols:
        # Convert non-numerical values to NaN and fill with mean
        df[col] = pd.to_numeric(df[col], errors = 'coerce')
        df[col] = df[col].fillna(df[col].mean())

    # Remove duplicates
    df = df.drop_duplicates()

    return df, categorical_cols, numerical_cols


# Apply the function 'identify_and_clean' on the appended_df DataFrame
df, categorical_cols, numerical_cols = identify_and_clean(appended_df)


df.head(2)


categorical_cols


numerical_cols


# Function to return descriptive statistics 
def descriptive_starts(df, categorical_cols, numerical_cols):
    # Descriptive statistics for numerical columns
    numerical_stats = df[numerical_cols].describe()

    # Descriptive statistics for categorical columns
    categorical_stats = df[categorical_cols].describe()

    return numerical_stats, categorical_stats


# Apply the stats functions
numerical_stats, categorical_stats = descriptive_starts(df, categorical_cols, numerical_cols)


round(numerical_stats.T,0)


categorical_stats.T



